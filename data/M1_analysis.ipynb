{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c9694d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Unified file list: (file_path, snapshot_name, table_name) ---\n",
    "all_files = [\n",
    "    # Assemblies\n",
    "    (r\"..\\data\\PreNexPartAssemblies.csv\",           \"PreNex\",  \"assemblies\"),\n",
    "    (r\"..\\data\\PartAssemblies_25_06_25.csv\",         \"PostNex\", \"assemblies\"),\n",
    "    (r\"..\\data\\PartAssembliesNGD27_30_06_25.csv\",    \"NGD27\",   \"assemblies\"),\n",
    "    (r\"..\\data\\PartAssembliesDammagedPost27.csv\",    \"Post27\",  \"assemblies\"),\n",
    "\n",
    "    # Revisions\n",
    "    (r\"..\\data\\PreNexPartRevisions.csv\",             \"PreNex\",  \"revisions\"),\n",
    "    (r\"..\\data\\PartRevisions_25_06_25.csv\",           \"PostNex\", \"revisions\"),\n",
    "    (r\"..\\data\\PartRevisionsNGD27_30_06_25.csv\",      \"NGD27\",   \"revisions\"),\n",
    "    (r\"..\\data\\PartRevisionsDammagedPost27.csv\",      \"Post27\",  \"revisions\"),\n",
    "\n",
    "    # Materials\n",
    "    (r\"..\\data\\PreNexPartMaterials.csv\",              \"PreNex\",  \"materials\"),\n",
    "    (r\"..\\data\\PartMaterials_25_06_25.csv\",            \"PostNex\", \"materials\"),\n",
    "    (r\"..\\data\\PartMaterialsNGD27_30_06_25.csv\",       \"NGD27\",   \"materials\"),\n",
    "    (r\"..\\data\\PartMaterialsDammagedPost27.csv\",       \"Post27\",  \"materials\"),\n",
    "]\n",
    "\n",
    "# --- Load into nested dictionary: dfs_snapshots[snapshot][table] ---\n",
    "dfs_snapshots = defaultdict(dict)\n",
    "\n",
    "DATE_FORMAT = \"%d/%m/%Y %I:%M:%S %p\"  # dd/mm/yyyy h:mm:ss AM/PM\n",
    "\n",
    "def parse_mixed_dates(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Parse a series of date strings that may be in either:\n",
    "      - \"%d/%m/%Y %I:%M:%S %p\"  (12h + AM/PM)\n",
    "      - \"%d/%m/%Y %H:%M\"        (24h, no AM/PM)\n",
    "    \"\"\"\n",
    "    # First pass: 12-hour clock with AM/PM\n",
    "    dt = pd.to_datetime(\n",
    "        series,\n",
    "        format=\"%d/%m/%Y %I:%M:%S %p\",\n",
    "        errors=\"coerce\",\n",
    "        dayfirst=True,\n",
    "    )\n",
    "\n",
    "    # Any failures -> try 24-hour clock\n",
    "    mask = dt.isna() & series.notna()\n",
    "    if mask.any():\n",
    "        dt.loc[mask] = pd.to_datetime(\n",
    "            series[mask],\n",
    "            format=\"%d/%m/%Y %H:%M\",\n",
    "            errors=\"coerce\",\n",
    "            dayfirst=True,\n",
    "        )\n",
    "    return dt\n",
    "\n",
    "def load_csv_with_dates(path: str) -> pd.DataFrame:\n",
    "    # 1) Peek header to find date columns\n",
    "    cols = pd.read_csv(path, nrows=0).columns\n",
    "    date_cols = [c for c in cols if c.endswith(\"CreatedDate\")]\n",
    "\n",
    "    # 2) Read all as strings for date cols (faster CSV read)\n",
    "    dtype = {c: pd.StringDtype() for c in date_cols}\n",
    "    df = pd.read_csv(path, dtype=dtype)\n",
    "\n",
    "    # 3) Convert detected date columns using mixed parser\n",
    "    for c in date_cols:\n",
    "        df[c] = parse_mixed_dates(df[c])\n",
    "\n",
    "    return df\n",
    "\n",
    "for path, snapshot, table in all_files:\n",
    "    dfs_snapshots[snapshot][table] = load_csv_with_dates(path)\n",
    "\n",
    "#ast to regular dict if you're done mutating\n",
    "dfs_snapshots = dict(dfs_snapshots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "efd9a7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imaPartID', 'imaPartRevisionID', 'imaMethodID', 'imaMethodRevisionID', 'imaMethodAssemblyID', 'imaPartShortDescription', 'imaCreatedBy', 'imaCreatedDate']\n",
      "['imaPartID', 'imaPartRevisionID', 'imaMethodID', 'imaMethodRevisionID', 'imaMethodAssemblyID', 'imaPartShortDescription', 'imaCreatedBy', 'imaCreatedDate']\n",
      "['imaPartID', 'imaPartRevisionID', 'imaMethodID', 'imaMethodRevisionID', 'imaMethodAssemblyID', 'imaPartShortDescription', 'imaCreatedBy', 'imaCreatedDate']\n",
      "['imaPartID', 'imaPartRevisionID', 'imaMethodID', 'imaMethodRevisionID', 'imaMethodAssemblyID', 'imaPartShortDescription', 'imaCreatedBy', 'imaCreatedDate']\n",
      "['imrPartID', 'imrPartRevisionID', 'imrShortDescription', 'imrCreatedBy', 'imrCreatedDate']\n",
      "['imrPartID', 'imrPartRevisionID', 'imrShortDescription', 'imrCreatedBy', 'imrCreatedDate']\n",
      "['imrPartID', 'imrPartRevisionID', 'imrShortDescription', 'imrCreatedBy', 'imrCreatedDate']\n",
      "['imrPartID', 'imrPartRevisionID', 'imrShortDescription', 'imrCreatedBy', 'imrCreatedDate']\n",
      "['immPartID', 'immPartRevisionID', 'immMethodID', 'immMethodRevisionID', 'immMethodAssemblyID', 'immPartShortDescription', 'immCreatedBy', 'immCreatedDate', 'immMethodMaterialID']\n",
      "['immPartID', 'immPartRevisionID', 'immMethodID', 'immMethodRevisionID', 'immMethodAssemblyID', 'immPartShortDescription', 'immCreatedBy', 'immCreatedDate', 'immMethodMaterialID']\n",
      "['immPartID', 'immPartRevisionID', 'immMethodID', 'immMethodRevisionID', 'immMethodAssemblyID', 'immPartShortDescription', 'immCreatedBy', 'immCreatedDate', 'immMethodMaterialID']\n",
      "['immPartID', 'immPartRevisionID', 'immMethodID', 'immMethodRevisionID', 'immMethodAssemblyID', 'immPartShortDescription', 'immCreatedBy', 'immCreatedDate', 'immMethodMaterialID']\n"
     ]
    }
   ],
   "source": [
    "for file_path, snapshot_name, table_name in all_files:\n",
    "    print(dfs_snapshots[snapshot_name][table_name].columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3c4413aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define index columns per table\n",
    "index_map = {\n",
    "    \"assemblies\": [\"imaPartID\", \"imaPartRevisionID\", 'imaMethodID', 'imaMethodRevisionID', 'imaMethodAssemblyID'],\n",
    "    \"revisions\": [\"imrPartID\", \"imrPartRevisionID\", \"imrCreatedBy\"],\n",
    "    \"materials\": [\"immPartID\", \"immPartRevisionID\", 'immMethodID', 'immMethodRevisionID', 'immMethodAssemblyID','immMethodMaterialID']\n",
    "}\n",
    "\n",
    "# Loop snapshots and tables\n",
    "for snapshot, tables in dfs_snapshots.items():\n",
    "    for table, df in tables.items():\n",
    "        if table in index_map:\n",
    "            dfs_snapshots[snapshot][table] = df.set_index(index_map[table])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fa648d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imrShortDescription', 'imrCreatedDate']\n",
      "['imrPartID', 'imrPartRevisionID', 'imrCreatedBy']\n",
      "imrShortDescription            object\n",
      "imrCreatedDate         datetime64[ns]\n",
      "dtype: object\n",
      "['imrShortDescription', 'imrCreatedDate']\n",
      "['imrPartID', 'imrPartRevisionID', 'imrCreatedBy']\n",
      "imrShortDescription            object\n",
      "imrCreatedDate         datetime64[ns]\n",
      "dtype: object\n",
      "['imrShortDescription', 'imrCreatedDate']\n",
      "['imrPartID', 'imrPartRevisionID', 'imrCreatedBy']\n",
      "imrShortDescription            object\n",
      "imrCreatedDate         datetime64[ns]\n",
      "dtype: object\n",
      "['imrShortDescription', 'imrCreatedDate']\n",
      "['imrPartID', 'imrPartRevisionID', 'imrCreatedBy']\n",
      "imrShortDescription            object\n",
      "imrCreatedDate         datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#test check for column names and index names\n",
    "for snapshot, tables in dfs_snapshots.items():\n",
    "    for table, df in tables.items():\n",
    "        if table == 'revisions':\n",
    "            print(dfs_snapshots[snapshot][table].columns.tolist())\n",
    "            print(dfs_snapshots[snapshot][table].index.names)\n",
    "            print(dfs_snapshots[snapshot][table].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b8e4640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#\"report\" (default): donâ€™t change data; just return dupe reports (no diff if dupes exist).\n",
    "#\"sequence\": add a per-key __seq__ to disambiguate multiplicity and proceed.\n",
    "#\"drop_exact\": drop exact duplicate rows (content-identical) before diffing.\n",
    "\n",
    "def _dupe_counts(df, key_cols):\n",
    "    g = df.reset_index()[key_cols].value_counts(sort=False).rename(\"count\")\n",
    "    return g[g > 1].sort_index()\n",
    "\n",
    "def _add_seq_index(df, key_cols, seq_name=\"__seq__\"):\n",
    "    # Keep original order per key; assign 0..n-1\n",
    "    if list(df.index.names) == key_cols:\n",
    "        df = df.reset_index()\n",
    "    df = df.copy()\n",
    "    df[seq_name] = df.groupby(key_cols).cumcount()\n",
    "    return df.set_index(key_cols + [seq_name])\n",
    "\n",
    "def _drop_exact_dupes(df, key_cols):\n",
    "    return df.reset_index().drop_duplicates().set_index(key_cols)\n",
    "\n",
    "def _row_hashes(df):\n",
    "    # Stable, vectorized row hash (handles NaNs)\n",
    "    h = np.zeros(len(df), dtype=np.uint64)\n",
    "    for c in df.columns:\n",
    "        h ^= pd.util.hash_pandas_object(df[c], index=False).to_numpy(dtype=np.uint64, copy=False)\n",
    "    return h\n",
    "\n",
    "def normalize_for_diff(df):\n",
    "    out = df.copy()\n",
    "\n",
    "    # IDs\n",
    "    if \"imrPartID\" in out.columns:\n",
    "        out[\"imrPartID\"] = out[\"imrPartID\"].astype(\"string\").str.strip()\n",
    "\n",
    "    if \"imrPartRevisionID\" in out.columns:\n",
    "        out[\"imrPartRevisionID\"] = (\n",
    "            out[\"imrPartRevisionID\"]\n",
    "            .astype(\"string\")\n",
    "            .str.strip()\n",
    "            .fillna(\"\")  # sentinel for missing revision\n",
    "        )\n",
    "\n",
    "    # Normalize strings\n",
    "    str_cols = out.select_dtypes(include=[\"object\", \"string\"]).columns\n",
    "    out[str_cols] = out[str_cols].apply(\n",
    "        lambda s: s.astype(\"string\").str.strip().replace({\"\": pd.NA})\n",
    "    )\n",
    "\n",
    "    # Normalize dates\n",
    "    for c in out.columns:\n",
    "        if c.endswith(\"CreatedDate\"):\n",
    "            out[c] = pd.to_datetime(out[c], errors=\"coerce\").dt.floor(\"min\")\n",
    "\n",
    "    return out\n",
    "    \n",
    "def fast_anycol_diff(\n",
    "    pre,\n",
    "    post,\n",
    "    key_cols,\n",
    "    label_pre=\"PreNex\",\n",
    "    label_post=\"PostNex\",\n",
    "    duplicate_strategy=\"report\",  # 'report' | 'sequence' | 'drop_exact'\n",
    "):\n",
    "    \"\"\"\n",
    "    Fast diff across ANY columns, with duplicate detection/handling.\n",
    "\n",
    "    Returns dict:\n",
    "      - changed_diff, changed_side_by_side, new_rows, removed_rows\n",
    "      - duplicates_pre, duplicates_post, duplicate_count_diff\n",
    "      - meta: info about strategy applied\n",
    "    \"\"\"\n",
    "     # --- normalize snapshots\n",
    "    df_pre = normalize_for_diff(pre)\n",
    "    df_post = normalize_for_diff(post)\n",
    "\n",
    "    # Ensure indexed by key (no copy if already correct)\n",
    "    if list(df_pre.index.names) != key_cols:\n",
    "        df_pre = df_pre.set_index(key_cols, drop=True)\n",
    "    if list(df_post.index.names) != key_cols:\n",
    "        df_post = df_post.set_index(key_cols, drop=True)\n",
    "\n",
    "    # --- Duplicate detection\n",
    "    dup_pre  = _dupe_counts(df_pre,  key_cols)\n",
    "    dup_post = _dupe_counts(df_post, key_cols)\n",
    "\n",
    "    # Differences in multiplicity (including 0â†’n, nâ†’0)\n",
    "    cnt_pre  = df_pre.reset_index()[key_cols].value_counts(sort=False).rename(\"count_pre\")\n",
    "    cnt_post = df_post.reset_index()[key_cols].value_counts(sort=False).rename(\"count_post\")\n",
    "    duplicate_count_diff = (\n",
    "        cnt_pre.to_frame().join(cnt_post.to_frame(), how=\"outer\").fillna(0).astype(int)\n",
    "    )\n",
    "    duplicate_count_diff = duplicate_count_diff[\n",
    "        (duplicate_count_diff[\"count_pre\"] != 1) | (duplicate_count_diff[\"count_post\"] != 1)\n",
    "    ].sort_index()\n",
    "\n",
    "    # Optionally resolve before diff\n",
    "    resolved = False\n",
    "    if duplicate_strategy == \"sequence\":\n",
    "        df_pre = _add_seq_index(df_pre, key_cols)\n",
    "        df_post = _add_seq_index(df_post, key_cols)\n",
    "        key_cols = df_pre.index.names  # now includes '__seq__' where applied\n",
    "        resolved = True\n",
    "    elif duplicate_strategy == \"drop_exact\":\n",
    "        if not dup_pre.empty:\n",
    "            df_pre = _drop_exact_dupes(df_pre, key_cols)\n",
    "        if not dup_post.empty:\n",
    "            df_post = _drop_exact_dupes(df_post, key_cols)\n",
    "        resolved = True\n",
    "    elif duplicate_strategy != \"report\":\n",
    "        raise ValueError(\"duplicate_strategy must be 'report', 'sequence', or 'drop_exact'\")\n",
    "\n",
    "    # If reporting only and duplicates exist, return reports without diffing\n",
    "    if duplicate_strategy == \"report\" and (not dup_pre.empty or not dup_post.empty):\n",
    "        return {\n",
    "            \"changed_diff\": pd.DataFrame(),\n",
    "            \"changed_side_by_side\": pd.DataFrame(),\n",
    "            \"new_rows\": pd.DataFrame(),\n",
    "            \"removed_rows\": pd.DataFrame(),\n",
    "            \"duplicates_pre\": dup_pre,\n",
    "            \"duplicates_post\": dup_post,\n",
    "            \"duplicate_count_diff\": duplicate_count_diff,\n",
    "            \"meta\": {\"duplicate_strategy\": \"report\", \"diff_performed\": False},\n",
    "        }\n",
    "\n",
    "    # --- Proceed with diff (unique rows per key at this point)\n",
    "    common  = df_pre.index.intersection(df_post.index)\n",
    "    added   = df_post.index.difference(df_pre.index)\n",
    "    removed = df_pre.index.difference(df_post.index)\n",
    "\n",
    "    cols = df_pre.columns.union(df_post.columns)\n",
    "    pre_common  = df_pre.loc[common].reindex(columns=cols)\n",
    "    post_common = df_post.loc[common].reindex(columns=cols)\n",
    "\n",
    "    # Hash rows to find changed keys fast\n",
    "    h_pre  = _row_hashes(pre_common)\n",
    "    h_post = _row_hashes(post_common)\n",
    "    changed_mask = h_pre != h_post\n",
    "    if changed_mask.any():\n",
    "        changed_idx = pre_common.index[changed_mask]\n",
    "        changed_side_by_side = pd.concat(\n",
    "            [\n",
    "                pre_common.loc[changed_idx].add_suffix(f\"_{label_pre}\"),\n",
    "                post_common.loc[changed_idx].add_suffix(f\"_{label_post}\"),\n",
    "            ],\n",
    "            axis=1,\n",
    "        ).reset_index()\n",
    "        changed_diff = post_common.loc[changed_idx].compare(\n",
    "            pre_common.loc[changed_idx],\n",
    "            align_axis=1,\n",
    "            keep_equal=False,\n",
    "            result_names=(label_post, label_pre),\n",
    "        )\n",
    "    else:\n",
    "        changed_side_by_side = pd.DataFrame(columns=list(key_cols))\n",
    "        changed_diff = pd.DataFrame()\n",
    "\n",
    "    new_rows     = df_post.loc[added].reset_index()\n",
    "    removed_rows = df_pre.loc[removed].reset_index()\n",
    "\n",
    "    return {\n",
    "        \"changed_diff\": changed_diff,\n",
    "        \"changed_side_by_side\": changed_side_by_side,\n",
    "        \"new_rows\": new_rows,\n",
    "        \"removed_rows\": removed_rows,\n",
    "        \"duplicates_pre\": dup_pre,\n",
    "        \"duplicates_post\": dup_post,\n",
    "        \"duplicate_count_diff\": duplicate_count_diff,\n",
    "        \"meta\": {\"duplicate_strategy\": \"sequence\" if resolved else duplicate_strategy, \"diff_performed\": True},\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a5d2b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreNex: total=30589, dup_rows=0, dup_keys=0\n",
      "NGD27: total=30694, dup_rows=2, dup_keys=1\n"
     ]
    }
   ],
   "source": [
    "key = ['imrPartID','imrPartRevisionID']\n",
    "pre = dfs_snapshots['PreNex']['revisions']\n",
    "post = dfs_snapshots['NGD27']['revisions']\n",
    "def dup_report(df, name):\n",
    "    dups = df.index.duplicated(keep=False)\n",
    "    print(f\"{name}: total={len(df)}, dup_rows={dups.sum()}, dup_keys={df.index[dups].nunique()}\")\n",
    "\n",
    "dup_report(pre,  \"PreNex\")\n",
    "dup_report(post, \"NGD27\")\n",
    "\n",
    "# See some examples\n",
    "#print(pre[pre.index.duplicated(keep=False)].head(10))\n",
    "#print(post[post.index.duplicated(keep=False)].head(10))\n",
    "\n",
    "#print(pre.loc[\"VSTS2MACK01\"])\n",
    "#print(post.loc[\"VSTS2MACK01\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4f44e19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                imrPartID imrPartRevisionID  imrCreatedBy  __seq__                 imrShortDescription_PreNex imrCreatedDate_PreNex                        imrShortDescription_PostNex imrCreatedDate_PostNex\n",
      "0  BUSTECH STICKER - 40OF                 A  David.Engman      0.0     BT LOGO 2 LAYER VINYL / MATTE LAMINATE   2023-10-06 10:07:00                  DECAL-BLANKING-EXIT HAMMER REWORK    2023-10-06 10:07:00\n",
      "1           IFVT-EX01-270                 A    Lana.Savic      0.0  38.1mm Single-Channel Aluminium Extrusion   2024-06-26 16:37:00  38.1mm Single-Channel Aluminium Extrusion - 270mm    2024-06-26 16:37:00\n"
     ]
    }
   ],
   "source": [
    "#PreNex, PostNex, NGD27, Post27    \n",
    "check = 'revisions'\n",
    "pre = dfs_snapshots['PreNex'][check]\n",
    "post = dfs_snapshots['PostNex'][check]\n",
    "#print(pre.head())\n",
    "#print(post.head())\n",
    "out = fast_anycol_diff(pre, post, index_map[check], duplicate_strategy=\"sequence\")\n",
    "# out['changed_diff'], out['changed_side_by_side'], out['new_rows'], out['removed_rows']\n",
    "print(out['changed_side_by_side'].to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d1a29894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           immPartID immPartRevisionID immMethodID immMethodRevisionID  immMethodAssemblyID  immMethodMaterialID  __seq__                             immPartShortDescription immCreatedBy      immCreatedDate\n",
      "0       DCL-BTGP-001                 A   MKFN-0004                   B                    0                    2      0.0                BUSTECH GROUP LOGO - SUIT FRONT DOOR   Lana.Savic 2024-12-06 12:13:00\n",
      "1       DCL-BTGP-002                 A   MKFN-0004                   B                    0                    3      0.0               BUSTECH GROUP LOGO - SUIT REAR HEADER   Lana.Savic 2024-12-06 12:13:00\n",
      "2        DCL-BUS-010               NaN   MKFN-0004                   B                    0                    4      NaN                       EMERGENCY EXIT DECAL INTERIOR   Lana.Savic 2024-12-06 12:13:00\n",
      "3        DCL-BUS-013               NaN   MKFN-0004                   B                    0                   15      NaN                                        DECAL ADBLUE   Lana.Savic 2024-12-06 12:13:00\n",
      "4        DCL-BUS-014               NaN   MKFN-0004                   B                    0                   14      NaN                                        DECAL DIESEL   Lana.Savic 2024-12-06 12:13:00\n",
      "5        DCL-BUS-019               NaN   MKFN-0004                   B                    0                   11      NaN                       DECAL MOTHER & CHILD (SCHOOL)   Lana.Savic 2024-12-06 12:13:00\n",
      "6        DCL-BUS-026               NaN   MKFN-0004                   B                    0                   19      NaN      DCL - WARNING CLOSED CIRCUIT TELEVISION IN USE   Lana.Savic 2024-12-06 12:13:00\n",
      "7        DCL-BUS-041               NaN   MKFN-0004                   B                    0                   21      NaN   DECAL FIRE EXTINGUISHER + DOWN ARROW-RED ON WHITE   Lana.Savic 2024-12-06 12:13:00\n",
      "8        DCL-BUS-048               NaN   MKFN-0004                   B                    0                   12      NaN                           DECAL WHEELCHAIR 2 SPACES   Lana.Savic 2024-12-06 12:13:00\n",
      "9        DCL-BUS-059               NaN   MKFN-0004                   B                    0                    5      NaN                             DECAL- HEARING AID LOOP   Lana.Savic 2024-12-06 12:13:00\n",
      "10       DCL-BUS-068               ORG   MKFN-0004                   B                    0                   22      0.0           Decal Emergency Door Lift Flap â€“ Exterior   Lana.Savic 2024-12-06 12:13:00\n",
      "11       DCL-BUS-069              ORIG   MKFN-0004                   B                    0                   23      0.0           Decal Emergency Door Lift Flap â€“ Interior   Lana.Savic 2024-12-06 12:13:00\n",
      "12      DCL-PLS-HAIL               NaN   MKFN-0004                   B                    0                   18      NaN                DECAL-PLEASE HAIL DRIVER & HANDPRINT   Lana.Savic 2024-12-06 12:13:00\n",
      "13       DCL-STA-083               NaN   MKFN-0004                   B                    0                    6      NaN                          PARK BRAKE MUST BE APPLIED   Lana.Savic 2024-12-06 12:13:00\n",
      "14       DCL-STA-132               NaN   MKFN-0004                   B                    0                   16      NaN  DECAL - IN EMERGENCY BREAK GLASS (INTERIOR)120X120   Lana.Savic 2024-12-06 12:13:00\n",
      "15       DCL-STA-134               NaN   MKFN-0004                   B                    0                   17      NaN  DECAL - IN EMERGENCY BREAK GLASS (EXTERIOR)120X120   Lana.Savic 2024-12-06 12:13:00\n",
      "16       DCL-STA-180               NaN   MKFN-0004                   B                    0                   25      NaN                       DECAL EMERGENCY EXIT EXTERIOR   Lana.Savic 2024-12-06 12:13:00\n",
      "17       DCL-STA-205               NaN   MKFN-0004                   B                    0                    7      NaN                           DECAL - WHEELCHAIR SYMBOL   Lana.Savic 2024-12-06 12:13:00\n",
      "18   DCL-STA-230/NSW               NaN   MKFN-0004                   B                    0                    8      NaN                      DECAL-ELDERLY/DISABLED SEATING   Lana.Savic 2024-12-06 12:13:00\n",
      "19       DCL-STA-240               NaN   MKFN-0004                   B                    0                    9      NaN                        WHEELCHAIR & PRAM SAFETY N/S   Lana.Savic 2024-12-06 12:13:00\n",
      "20       DCL-STA-241               NaN   MKFN-0004                   B                    0                   10      NaN                        WHEELCHAIR & PRAM SAFETY O/S   Lana.Savic 2024-12-06 12:13:00\n",
      "21       DCL-STA-300               NaN   MKFN-0004                   B                    0                   13      NaN                                      GIVE WAY DECAL   Lana.Savic 2024-12-06 12:13:00\n",
      "22       DCL-STA-320               NaN   MKFN-0004                   B                    0                   20      NaN             DECAL - DO NOT OVERTAKE TURNING VEHICLE   Lana.Savic 2024-12-06 12:13:00\n",
      "23         SWVT-0001              2.12   MKPD-0004                   A                    0                    1      0.0                           Scania NGB Thoreb Project  Daniel.Boyd 2024-07-18 14:59:00\n",
      "24  YELLOW-TAPE-25MM              ORIG   MKFN-0004                   B                    0                   24      0.0                 25mm wide 3M bright yellow 45M roll   Lana.Savic 2024-12-06 12:13:00\n"
     ]
    }
   ],
   "source": [
    "#PreNex, PostNex, NGD27, Post27    \n",
    "check = 'materials'\n",
    "pre = dfs_snapshots['PreNex'][check]\n",
    "post = dfs_snapshots['Post27'][check]\n",
    "#print(pre.head())\n",
    "#print(post.head())\n",
    "out = fast_anycol_diff(pre, post, index_map[check], duplicate_strategy=\"sequence\")\n",
    "# out['changed_diff'], out['changed_side_by_side'], out['new_rows'], out['removed_rows']\n",
    "print(out['removed_rows'].to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "019b76e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                imaPartID imaPartRevisionID             imaMethodID imaMethodRevisionID  imaMethodAssemblyID  __seq__                      imaPartShortDescription_PreNex imaCreatedBy_PreNex imaCreatedDate_PreNex                    imaPartShortDescription_PostNex imaCreatedBy_PostNex imaCreatedDate_PostNex\n",
      "0  BUSTECH STICKER - 40OF                 A  BUSTECH STICKER - 40OF                   A                    0      0.0              BT LOGO 2 LAYER VINYL / MATTE LAMINATE                <NA>                   NaT                  DECAL-BLANKING-EXIT HAMMER REWORK                 <NA>                    NaT\n",
      "1               FGGN-OD08              ORIG               FGGN-OD08                ORIG                    0      0.0  VST-F/GLASS-WHITE A/C DUCT ACCESS DOOR-CHROME LOCK                <NA>                   NaT             VST-F/GLASS-WHITE A/C DUCT ACCESS DOOR                 <NA>                    NaT\n",
      "2           IFVT-EX01-270                 A           IFVT-EX01-270                   A                    0      0.0           38.1mm Single-Channel Aluminium Extrusion                <NA>                   NaT  38.1mm Single-Channel Aluminium Extrusion - 270mm                 <NA>                    NaT\n",
      "3                 WELDROD            YS-TRI                 WELDROD              YS-TRI                    0      0.0                        Weld Cord CR72 Yellston 4521                <NA>                   NaT                       Weld Cord CA72 Yellston 4521                 <NA>                    NaT\n"
     ]
    }
   ],
   "source": [
    "#PreNex, PostNex, NGD27, Post27    \n",
    "check = 'assemblies'\n",
    "pre = dfs_snapshots['PreNex'][check]\n",
    "post = dfs_snapshots['Post27'][check]\n",
    "#print(pre.head())\n",
    "#print(post.head())\n",
    "out = fast_anycol_diff(pre, post, index_map[check], duplicate_strategy=\"sequence\")\n",
    "# out['changed_diff'], out['changed_side_by_side'], out['new_rows'], out['removed_rows']\n",
    "print(out['changed_side_by_side'].to_string())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
